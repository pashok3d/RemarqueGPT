{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEFqCtLwcDVOH3MYFY2EXK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pashok3d/RemarqueGPT/blob/main/Lets_build_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "7FloGrMdQrw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs\n",
        "\n",
        "!pip install tiktoken -q\n",
        "!pip install ipdb -q"
      ],
      "metadata": {
        "id": "EpulYfml2T6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62288bae-f129-4102-98c0-2026dddbd875"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import tiktoken\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "tEbhNV_U62AI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb on"
      ],
      "metadata": {
        "id": "IxzyxdZ7OJK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eee486a-eba3-461f-8b0f-7f4a808e5fa6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset loading and processing"
      ],
      "metadata": {
        "id": "DFKzl6Lv-NKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/the_dream_room.txt\", \"r\") as f:\n",
        "    lines = f.readlines()"
      ],
      "metadata": {
        "id": "SPGkaHjW48Af"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = [l.replace('\\xa0', ' ').strip() for l in lines if l.strip()]"
      ],
      "metadata": {
        "id": "qlmMv45h5rue"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\\n\".join(lines)"
      ],
      "metadata": {
        "id": "ONGvYPBn5KUZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "BAFPik4t6xWO",
        "outputId": "62b2a56a-577f-49af-96d8-66859e7d9a02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'В цветущих садах веял майский ветерок От веток сирени, нависавших над оградой старой кладки, доносился густой сладкий аромат. Художник Фриц Шрамм медленно бродил по старинным переулкам городка. Время '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc = tiktoken.encoding_for_model(\"gpt-4o\")"
      ],
      "metadata": {
        "id": "DuvqEULn65VB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = enc.encode_ordinary(text)"
      ],
      "metadata": {
        "id": "GpMTRuan7KMh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_token_len = len(tokens)"
      ],
      "metadata": {
        "id": "9QwxiprI9Jc_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_token_id_to_local_id = {\n",
        "    token: i+1 for i, token in enumerate(set(tokens))\n",
        "}"
      ],
      "metadata": {
        "id": "sF7s_ah57VkZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_id_to_gpt_token_id = {\n",
        "    v: k for k, v in gpt_token_id_to_local_id.items()\n",
        "}"
      ],
      "metadata": {
        "id": "Uixc_v0d8GHn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text) -> List[int]:\n",
        "    tokens = enc.encode_ordinary(text)\n",
        "    return [gpt_token_id_to_local_id[token] for token in tokens]\n",
        "\n",
        "def decode(tokens: List[int]) -> str:\n",
        "    return enc.decode([local_id_to_gpt_token_id[token] for token in tokens])"
      ],
      "metadata": {
        "id": "BK1QE9P18Sv1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(set(tokens))"
      ],
      "metadata": {
        "id": "aux4pxdo9lgg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader"
      ],
      "metadata": {
        "id": "ctxxkVHx-SvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, text, context_window_size):\n",
        "        self.gpt_tokens = enc.encode_ordinary(text)\n",
        "        self.tokens = [gpt_token_id_to_local_id[token] for token in self.gpt_tokens]\n",
        "\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        for i in range(len(self.tokens) - context_window_size):\n",
        "            self.x.append(self.tokens[i:i+context_window_size])\n",
        "            self.y.append(self.tokens[i+1:i+context_window_size+1])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx) -> Tuple:\n",
        "        return torch.tensor(self.x[idx]), torch.tensor(self.y[idx])"
      ],
      "metadata": {
        "id": "Mk7cEwXVCEJM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 6"
      ],
      "metadata": {
        "id": "Th08N4f5q_tJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = TextDataset(text, T)"
      ],
      "metadata": {
        "id": "L3wJTfFPD9MG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB-jRGXJEACx",
        "outputId": "3caa0756-86cc-4e64-fc16-e084027fd0af"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1540,  703, 1282, 2069, 1551,  331]),\n",
              " tensor([ 703, 1282, 2069, 1551,  331, 1663]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B = 5"
      ],
      "metadata": {
        "id": "XCiRxo0kq9eH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(ds, batch_size=B, shuffle=True)"
      ],
      "metadata": {
        "id": "9SD0H2LLEKAN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lq7TIe8Lqs5",
        "outputId": "91a1114a-1943-4a47-b733-e1e1036bd704"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[2765, 2930,  562,    8, 2464,   76],\n",
              "         [ 501,  899, 2046,  335, 1808,  248],\n",
              "         [   6, 1000,  665, 1828, 1096, 1463],\n",
              "         [ 169, 2665, 2955, 2188,  339, 2155],\n",
              "         [ 375,  585,  503,  581, 1121,   29]]),\n",
              " tensor([[2930,  562,    8, 2464,   76, 1759],\n",
              "         [ 899, 2046,  335, 1808,  248,  736],\n",
              "         [1000,  665, 1828, 1096, 1463,  299],\n",
              "         [2665, 2955, 2188,  339, 2155, 2184],\n",
              "         [ 585,  503,  581, 1121,   29, 1241]])]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "YGa5qPmcNR6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding:\n",
        "    def __init__(self, vocab_size, emb_dim):\n",
        "        self.embedding_table = nn.Embedding(vocab_size, emb_dim)\n",
        "\n",
        "    def __call__(self, input):\n",
        "        return self.embedding_table(input)"
      ],
      "metadata": {
        "id": "dYLpfeyuBOw2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention:\n",
        "    def __init__(self, emb_dim, head_n):\n",
        "        self.emb_dim = emb_dim\n",
        "        self.QKV = nn.Linear(emb_dim, emb_dim * 3)\n",
        "        self.head_n = head_n\n",
        "\n",
        "    def __call__(self, input):\n",
        "        \"\"\"\n",
        "        input: shape (B, T, C)\n",
        "        \"\"\"\n",
        "\n",
        "        assert self.emb_dim % self.head_n == 0\n",
        "\n",
        "        # Calculate q, k, v\n",
        "        q, k, v = self.QKV(input).split(self.emb_dim, dim=-1)\n",
        "        q = q.view(B, T, self.head_n, self.emb_dim // self.head_n).transpose(1, 2) # (B, nh, T, hs)\n",
        "        k = k.view(B, T, self.head_n, self.emb_dim // self.head_n).transpose(1, 2)\n",
        "        v = v.view(B, T, self.head_n, self.emb_dim // self.head_n).transpose(1, 2)\n",
        "\n",
        "        # Multiply q and k\n",
        "        qk = q @ k.transpose(-2, -1)\n",
        "\n",
        "        # Mask\n",
        "        qk[torch.tril(torch.ones_like(qk)) == 0] = -torch.inf\n",
        "\n",
        "        # Softmax\n",
        "        qk_softmax = qk.softmax(dim=-1)\n",
        "\n",
        "        # Multiply by v\n",
        "        new_v = qk_softmax @ v\n",
        "\n",
        "        # Combine new values from multiple heads\n",
        "        output = new_v.transpose(1, 2).contiguous().view(B, T, self.emb_dim)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "9aBhWlVX7ol_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward:\n",
        "    def __init__(self, emb_dim):\n",
        "        self.m_1 = nn.Linear(emb_dim, emb_dim*2)\n",
        "        self.a = nn.ReLU()\n",
        "        self.m_2 = nn.Linear(emb_dim*2, emb_dim)\n",
        "\n",
        "    def __call__(self, input):\n",
        "        f1 = self.m_1(input)\n",
        "        z1 = self.a(f1)\n",
        "        f2 = self.m_2(z1)\n",
        "        return f2"
      ],
      "metadata": {
        "id": "_i3vZdSmBFET"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock:\n",
        "    def __init__(self, emb_dim, head_n):\n",
        "        self.mha = MultiHeadAttention(emb_dim, head_n)\n",
        "        self.ff = FeedForward(emb_dim)\n",
        "        self.mha_layer_norm = nn.LayerNorm(emb_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(emb_dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = x + self.mha(self.mha_layer_norm(x))\n",
        "        x = x + self.ff(self.ff_layer_norm(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "aHrbfNG6EUue"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder:\n",
        "    def __init__(self, vocab_size, emb_dim, num_blocks, head_n):\n",
        "        self.emb = Embedding(vocab_size, emb_dim)\n",
        "        self.blocks = [DecoderBlock(emb_dim, head_n) for _ in range(num_blocks)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.emb(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "OL5cpzmAEV0C"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = Decoder(vocab_size=vocab_size, emb_dim=16, num_blocks=3, head_n=4)"
      ],
      "metadata": {
        "id": "ocbNfY0yHzZD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = next(iter(dataloader))"
      ],
      "metadata": {
        "id": "5g7dgNscIwOJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = input[0]"
      ],
      "metadata": {
        "id": "8CxZBEtBIyIG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V5d88qfXCIA",
        "outputId": "5bf90abc-1c01-4894-f71f-0e183e465e8b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = d(x)"
      ],
      "metadata": {
        "id": "ThWh-ByfH6q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed986b9a-6a41-4270-a39d-b334c89476a6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape torch.Size([5, 6, 16])\n",
            "x.shape torch.Size([5, 6, 16])\n",
            "x.shape torch.Size([5, 6, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeoG9K9KJCla",
        "outputId": "acbf6b99-27d6-4bdc-ca28-6ba484f5016a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 6, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next steps:\n",
        "# 1. Generator: linear projection from last hidden state to vocab size\n",
        "# 2. Dropout\n",
        "# 3. Add scaling factor in attention calculation\n",
        "# 4. Positional Encoding"
      ],
      "metadata": {
        "id": "zDo0n9B2SHyy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}