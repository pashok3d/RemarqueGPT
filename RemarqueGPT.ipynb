{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pashok3d/RemarqueGPT/blob/main/RemarqueGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOv4_JlEx_Do"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Building GPT from scratch and training it on all books of Erich Maria Remarque\n",
        "\n",
        "Available tools: python, pytorch\n",
        "\n",
        "Tasks:\n",
        "1. Load data and tokenize to characters\n",
        "2. Implement GPT model using pytorch\n",
        "3. Train and evaluate the model\n",
        "\n",
        "GPT model structure:\n",
        "1. embedding layer\n",
        "2. positional encoding\n",
        "3. blocks\n",
        "    .1 attention\n",
        "    .2 feedforward\n",
        "4. projection\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q58f3NJEEW59"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm -q\n",
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VblH5Otza11y"
      },
      "outputs": [],
      "source": [
        "!mkdir dataset\n",
        "!mkdir model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e2yGAjdBx_Dq"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import torch\n",
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import ConcatDataset, Dataset\n",
        "from torch import nn\n",
        "import math\n",
        "from transformers import get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_8wJTDqx_Dq"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oVQJ4af2hixP"
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 64\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LR = 5e-4\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "config = {\n",
        "    \"learning_rate\": LR,\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"window_size\": WINDOW_SIZE,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyE91wOu52hG"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(project=\"remark-gpt\", config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jN-m4tUlZLl2"
      },
      "outputs": [],
      "source": [
        "def tokenize(text, token_to_id) -> list[int]:\n",
        "    return [token_to_id[ch] for ch in text]\n",
        "\n",
        "\n",
        "def decode(token_ids: list[int], id_to_token) -> str:\n",
        "    return \"\".join([id_to_token[token_id] for token_id in token_ids])\n",
        "\n",
        "\n",
        "def generate_text(\n",
        "    model,\n",
        "    token_to_id,\n",
        "    id_to_token,\n",
        "    prompt: str,\n",
        "    device: str,\n",
        "    window_size: int,\n",
        "    max_tokens: int = 10,\n",
        "    temperature: float = 1.0,\n",
        ") -> str:\n",
        "    \"\"\"Generate text using the trained GPT model.\"\"\"\n",
        "    model.eval()\n",
        "    context = tokenize(prompt, token_to_id)\n",
        "    generated = list(context)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_tokens):\n",
        "            x = torch.tensor(context[-window_size:]).unsqueeze(0).to(device)\n",
        "            logits, _ = model(x)\n",
        "            logits = logits[0, -1, :] / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
        "            generated.append(next_token)\n",
        "            context = generated\n",
        "\n",
        "    return decode(context, id_to_token)\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, path, context_window_size, token_to_id):\n",
        "        # Load dataset\n",
        "        with open(path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        text = \"\\n\".join(lines)\n",
        "\n",
        "        self.tokens = tokenize(text, token_to_id)\n",
        "\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        for i in range(len(self.tokens) - context_window_size):\n",
        "            self.x.append(self.tokens[i : i + context_window_size])\n",
        "            self.y.append(self.tokens[i + 1 : i + context_window_size + 1])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.x[idx]), torch.tensor(self.y[idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1cqziIlWJvDS"
      },
      "outputs": [],
      "source": [
        "# Prepare tokenizer\n",
        "dataset_lines = []\n",
        "with open(\"dataset/The_Dream_Room_1920_AST_978-5-17-071518-3.txt\", \"r\") as f:\n",
        "    dataset_lines.extend(f.readlines())\n",
        "with open(\"dataset/Station_at_the_Horizon_1928_AST_978-5-17-133322-5.txt\", \"r\") as f:\n",
        "    dataset_lines.extend(f.readlines())\n",
        "with open(\"dataset/All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1.txt\", \"r\") as f:\n",
        "    dataset_lines.extend(f.readlines())\n",
        "with open(\"dataset/All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0.txt\", \"r\") as f:\n",
        "    dataset_lines.extend(f.readlines())\n",
        "with open(\"dataset/The_Road_Back_1931.txt\", \"r\") as f:\n",
        "    dataset_lines.extend(f.readlines())\n",
        "text = \"\\n\".join(dataset_lines)\n",
        "tokens = sorted(set(text))\n",
        "id_to_token = {i: token for i, token in enumerate(tokens)}\n",
        "token_to_id = {token: i for i, token in enumerate(tokens)}\n",
        "\n",
        "train_ds1 = TextDataset(\n",
        "    \"dataset/The_Dream_Room_1920_AST_978-5-17-071518-3-train.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "train_ds2 = TextDataset(\n",
        "    \"dataset/Station_at_the_Horizon_1928_AST_978-5-17-133322-5.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "train_ds3 = TextDataset(\n",
        "    \"dataset/All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1-train.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "train_ds4 = TextDataset(\n",
        "    \"dataset/All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0-train.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "train_ds5 = TextDataset(\n",
        "    \"dataset/The_Road_Back_1931-train.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "train_ds = ConcatDataset([train_ds1, train_ds2, train_ds3, train_ds4, train_ds5])\n",
        "train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "dev_ds1 = TextDataset(\n",
        "    \"dataset/The_Dream_Room_1920_AST_978-5-17-071518-3-dev.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "dev_ds2 = TextDataset(\n",
        "    \"dataset/Station_at_the_Horizon_1928_AST_978-5-17-133322-5-dev.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "dev_ds3 = TextDataset(\n",
        "    \"dataset/All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1-dev.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "dev_ds4 = TextDataset(\n",
        "    \"dataset/All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0-dev.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "dev_ds5 = TextDataset(\n",
        "    \"dataset/The_Road_Back_1931-dev.txt\",\n",
        "    WINDOW_SIZE,\n",
        "    token_to_id,\n",
        ")\n",
        "\n",
        "dev_dataloader1 = DataLoader(dev_ds1, batch_size=BATCH_SIZE, shuffle=False)\n",
        "dev_dataloader2 = DataLoader(dev_ds2, batch_size=BATCH_SIZE, shuffle=False)\n",
        "dev_dataloader3 = DataLoader(dev_ds3, batch_size=BATCH_SIZE, shuffle=False)\n",
        "dev_dataloader4 = DataLoader(dev_ds4, batch_size=BATCH_SIZE, shuffle=False)\n",
        "dev_dataloader5 = DataLoader(dev_ds5, batch_size=BATCH_SIZE, shuffle=False)\n",
        "names_with_dev_dataloaders = [\n",
        "    (\"The_Dream_Room_1920_AST_978-5-17-071518-3\", dev_dataloader1),\n",
        "    (\"Station_at_the_Horizon_1928_AST_978-5-17-133322-5\", dev_dataloader2),\n",
        "    (\"All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1\", dev_dataloader3),\n",
        "    (\"All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0\", dev_dataloader4),\n",
        "    (\"The_Road_Back_1931\", dev_dataloader5)\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "hF-56wiUZteN"
      },
      "outputs": [],
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, embedding_dim, head_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.Q = nn.Linear(embedding_dim, head_dim, bias=False)\n",
        "        self.K = nn.Linear(embedding_dim, head_dim, bias=False)\n",
        "        self.V = nn.Linear(embedding_dim, head_dim, bias=False)\n",
        "\n",
        "        self.kv_softmax = nn.Softmax(dim=-1)\n",
        "        self.attn_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(max_len, max_len)))\n",
        "\n",
        "    def forward(self, norm_inputs):\n",
        "\n",
        "        _, T, _ = norm_inputs.shape\n",
        "\n",
        "        q = self.Q(norm_inputs)\n",
        "        k = self.K(norm_inputs)\n",
        "        v = self.V(norm_inputs)\n",
        "\n",
        "        attention_weights = (q @ k.transpose(-1, -2)) / math.sqrt(\n",
        "            q.shape[-1]\n",
        "        )  # shape: (B, T, T)\n",
        "        attention_weights_masked = attention_weights.masked_fill(\n",
        "            self.tril[:T, :T] == 0, -torch.inf\n",
        "        )\n",
        "        attention_scores = self.kv_softmax(attention_weights_masked)\n",
        "        attention_scores = self.attn_dropout(attention_scores)\n",
        "\n",
        "        return attention_scores @ v\n",
        "\n",
        "\n",
        "class GPTBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self, embedding_dim: int, max_len: int, dropout: float = 0.1, n_heads=2\n",
        "    ):\n",
        "        super().__init__()\n",
        "        head_dim = embedding_dim // n_heads\n",
        "\n",
        "        # Attention heads\n",
        "        self.heads = nn.ModuleList(\n",
        "            [\n",
        "                AttentionHead(embedding_dim, head_dim, dropout, max_len)\n",
        "                for _ in range(n_heads)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Feedforward\n",
        "        self.f1 = nn.Linear(embedding_dim, embedding_dim * 4)\n",
        "        self.f_act = nn.ReLU()\n",
        "        self.f2 = nn.Linear(embedding_dim * 4, embedding_dim)\n",
        "        self.ff_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.ln1 = nn.LayerNorm(embedding_dim)\n",
        "        self.ln2 = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        norm_inputs = self.ln1(inputs)\n",
        "        attn_out = torch.concat([h(norm_inputs) for h in self.heads], dim=-1)\n",
        "\n",
        "        # Add residual connection\n",
        "        x = inputs + attn_out\n",
        "\n",
        "        norm_x = self.ln2(x)\n",
        "        ff_out = self.ff_dropout(self.f2(self.f_act(self.f1(norm_x))))\n",
        "        out = x + ff_out\n",
        "        return out\n",
        "\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        max_len: int,\n",
        "        embedding_dim: int = 16,\n",
        "        blocks_num: int = 4,\n",
        "        n_heads: int = 2,\n",
        "        dropout: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.emb = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos = nn.Embedding(max_len, embedding_dim)\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[\n",
        "                GPTBlock(embedding_dim, max_len, dropout, n_heads)\n",
        "                for _ in range(blocks_num)\n",
        "            ]\n",
        "        )\n",
        "        self.proj = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, inputs, labels=None):\n",
        "        _, T = inputs.shape\n",
        "        embs = self.emb(inputs)\n",
        "        pos_embs = self.pos(torch.arange(T, device=inputs.device))  # (T,C)\n",
        "        blocks_output = self.blocks(embs + pos_embs)\n",
        "        logits = self.proj(blocks_output)  # (B,T,vocab_size)\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits.view(-1, self.vocab_size), labels.view(-1))\n",
        "            return logits, loss\n",
        "        else:\n",
        "            return logits, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pnf4aP9ywkjD"
      },
      "outputs": [],
      "source": [
        "model = GPT(vocab_size=len(tokens), max_len=WINDOW_SIZE, embedding_dim=64, blocks_num=6, n_heads=4)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "# Scheduler with warmup and linear decay\n",
        "TOTAL_STEPS = EPOCHS * len(train_dataloader)\n",
        "WARMUP_STEPS = int(0.1 * TOTAL_STEPS)  # 10% warmup\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=TOTAL_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HOZUqcOnwlIy"
      },
      "outputs": [],
      "source": [
        "wandb.watch(model, log_freq=2500, log='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSeQTdOowrhS"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "epoch_loss = 0\n",
        "steps_n = 0\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        input, labels = batch[0].to(device), batch[1].to(device)\n",
        "        output, loss = model(input, labels)\n",
        "        epoch_loss += loss.item()\n",
        "        steps_n += 1\n",
        "    avg_loss = epoch_loss / steps_n\n",
        "expected_init_loss = -math.log(1 / len(tokens))\n",
        "print(f\"initial train loss: {avg_loss:.3f}, with expected of {expected_init_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC3-JgvRwhxz",
        "outputId": "a76203b5-a9c4-40b8-9bcb-1edfae07f8de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:30<00:00, 57.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 train loss: 2.194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 163.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.760\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 163.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:02<00:00, 162.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 163.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 163.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 val loss for The_Road_Back_1931: 1.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:30<00:00, 57.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 train loss: 1.678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 164.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 163.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:02<00:00, 162.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 161.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 160.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 val loss for The_Road_Back_1931: 1.594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:28<00:00, 57.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 train loss: 1.603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 159.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 163.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:02<00:00, 163.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 164.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 162.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 val loss for The_Road_Back_1931: 1.563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:28<00:00, 57.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 train loss: 1.571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 157.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 164.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:02<00:00, 165.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 162.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 164.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 val loss for The_Road_Back_1931: 1.543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:29<00:00, 57.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 train loss: 1.550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 160.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 161.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:02<00:00, 164.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 160.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 160.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 val loss for The_Road_Back_1931: 1.531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:32<00:00, 57.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 train loss: 1.534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 162.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 162.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:02<00:00, 162.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 160.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 162.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 val loss for The_Road_Back_1931: 1.521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:30<00:00, 57.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6 train loss: 1.522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 162.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 163.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:03<00:00, 156.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 163.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 161.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6 val loss for The_Road_Back_1931: 1.512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:32<00:00, 57.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7 train loss: 1.512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 160.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 162.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:03<00:00, 161.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 163.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 163.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7 val loss for The_Road_Back_1931: 1.507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:30<00:00, 57.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8 train loss: 1.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 164.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 162.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:03<00:00, 158.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 163.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 163.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8 val loss for The_Road_Back_1931: 1.501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22516/22516 [06:31<00:00, 57.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9 train loss: 1.495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 397/397 [00:02<00:00, 162.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9 val loss for The_Dream_Room_1920_AST_978-5-17-071518-3: 1.536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:03<00:00, 161.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9 val loss for Station_at_the_Horizon_1928_AST_978-5-17-133322-5: 1.363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 485/485 [00:02<00:00, 163.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1: 1.559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 556/556 [00:03<00:00, 162.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9 val loss for All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0: 1.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 715/715 [00:04<00:00, 159.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9 val loss for The_Road_Back_1931: 1.497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    steps_n = 0\n",
        "\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        input, labels = batch[0].to(device), batch[1].to(device)\n",
        "        output, loss = model(input, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update the learning rate\n",
        "        optimizer.zero_grad()\n",
        "        epoch_loss += loss.item()\n",
        "        steps_n += 1\n",
        "        run.log({\"train_loss\": loss.item(), \"lr\": scheduler.get_last_lr()[0]})\n",
        "\n",
        "    avg_loss = epoch_loss / steps_n\n",
        "    print(f\"epoch {epoch} train loss: {avg_loss:.3f}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for ds_name, dev_dataloader in names_with_dev_dataloaders:\n",
        "            val_steps_n = 0\n",
        "            val_epoch_loss = 0\n",
        "            for batch in tqdm(dev_dataloader):\n",
        "                input, labels = batch[0].to(device), batch[1].to(device)\n",
        "                output, loss = model(input, labels)\n",
        "                val_epoch_loss += loss.item()\n",
        "                val_steps_n += 1\n",
        "            avg_val_loss = val_epoch_loss / val_steps_n\n",
        "            print(f\"epoch {epoch} val loss for {ds_name}: {avg_val_loss:.3f}\")\n",
        "            metric_name = f\"avg_val_loss_{ds_name}\"\n",
        "            run.log({metric_name: avg_val_loss}, commit=False)\n",
        "\n",
        "    run.log({\"avg_train_loss\": avg_loss})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e9eYiDoFRIou"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model/gpt.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "300VB3stx_Ds"
      },
      "outputs": [],
      "source": [
        "artifact = wandb.Artifact(\"model\", type=\"model\")\n",
        "artifact.add_file(\"model/gpt.pt\")\n",
        "run.log_artifact(artifact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "G5ytmLzkx_Ds",
        "outputId": "e1ce6779-921e-4ff5-f441-b5e7dff6375f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>avg_val_loss_All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1</td><td>█▄▃▂▂▂▂▁▁▁</td></tr><tr><td>avg_val_loss_All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>avg_val_loss_Station_at_the_Horizon_1928_AST_978-5-17-133322-5</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>avg_val_loss_The_Dream_Room_1920_AST_978-5-17-071518-3</td><td>█▄▃▂▂▂▂▁▁▁</td></tr><tr><td>avg_val_loss_The_Road_Back_1931</td><td>█▄▃▃▂▂▁▁▁▁</td></tr><tr><td>lr</td><td>▂▃█████▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>1.49547</td></tr><tr><td>avg_val_loss_All_Quiet_on_the_Western_Front_1929_AST_978-5-17-105639-1</td><td>1.55941</td></tr><tr><td>avg_val_loss_All_Quiet_on_the_Western_Front_1929_AST_978-5-17-137374-0</td><td>1.46373</td></tr><tr><td>avg_val_loss_Station_at_the_Horizon_1928_AST_978-5-17-133322-5</td><td>1.363</td></tr><tr><td>avg_val_loss_The_Dream_Room_1920_AST_978-5-17-071518-3</td><td>1.53615</td></tr><tr><td>avg_val_loss_The_Road_Back_1931</td><td>1.49668</td></tr><tr><td>lr</td><td>0</td></tr><tr><td>train_loss</td><td>1.50139</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">polished-wood-21</strong> at: <a href='https://wandb.ai/crush_tarash/remark-gpt/runs/4vby0f2h' target=\"_blank\">https://wandb.ai/crush_tarash/remark-gpt/runs/4vby0f2h</a><br> View project at: <a href='https://wandb.ai/crush_tarash/remark-gpt' target=\"_blank\">https://wandb.ai/crush_tarash/remark-gpt</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250102_151054-4vby0f2h/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsBjFtlUx_Ds",
        "outputId": "bee9527f-3822-413f-a754-228ac7213e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "– Привет, любовь моя!\n",
            "\n",
            "– А теперь ведь в то, что мы в причине появляемся. Потом следует нам в каждом поверхное возможно в портрет он на стальнике, завтра она не спрашивают в полусне с конца. Я поднимаю в напротивника, — го\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "prompt = \"– Привет, любовь моя!\\n\"\n",
        "generated_text = generate_text(\n",
        "    model,\n",
        "    token_to_id,\n",
        "    id_to_token,\n",
        "    prompt,\n",
        "    device,\n",
        "    window_size=WINDOW_SIZE,\n",
        "    max_tokens=200,\n",
        "    temperature=0.5\n",
        ")\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8DBnPUrme3P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
