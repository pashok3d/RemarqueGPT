{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pashok3d/RemarqueGPT/blob/main/RemarqueGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Building GPT from scratch and training it on all books of Erich Maria Remarque\n",
        "\n",
        "Available tools: python, pytorch\n",
        "\n",
        "Tasks:\n",
        "1. Load data and tokenize to characters\n",
        "2. Implement GPT model using pytorch\n",
        "3. Train and evaluate the model\n",
        "\n",
        "GPT model structure:\n",
        "1. embedding layer\n",
        "2. positional encoding\n",
        "3. blocks\n",
        "    .1 attention\n",
        "    .2 feedforward\n",
        "4. projection\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q58f3NJEEW59"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm -q\n",
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "HOe1c2RlJpSd",
        "outputId": "c1a18d73-fc97-4556-fe9d-5aff740edf66"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VblH5Otza11y"
      },
      "outputs": [],
      "source": [
        "!mkdir dataset\n",
        "!mkdir model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "import torch\n",
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from utils import TextDataset, generate_text\n",
        "from model import GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oVQJ4af2hixP"
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 64\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "LR = 5e-4\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "config = {\n",
        "    \"learning_rate\": LR,\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"window_size\": WINDOW_SIZE,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "JyE91wOu52hG",
        "outputId": "9671718b-60d5-4e9f-d834-cd702c741ed1"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(project=\"remark-gpt\", config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1cqziIlWJvDS"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "with open(\"dataset/The_Dream_Room_1920_AST_978-5-17-071518-3.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "text = \"\\n\".join(lines)\n",
        "tokens = sorted(set(text))\n",
        "\n",
        "# Load train dataset\n",
        "with open(\"dataset/The_Dream_Room_1920_AST_978-5-17-071518-3-train.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "train_text = \"\\n\".join(lines)\n",
        "\n",
        "# Load dev dataset\n",
        "with open(\"dataset/The_Dream_Room_1920_AST_978-5-17-071518-3-dev.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "dev_text = \"\\n\".join(lines)\n",
        "\n",
        "# Load dev dataset\n",
        "with open(\"dataset/The_Dream_Room_1920_AST_978-5-17-071518-3-test.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "test_text = \"\\n\".join(lines)\n",
        "\n",
        "id_to_token = {i: token for i, token in enumerate(tokens)}\n",
        "token_to_id = {token: i for i, token in enumerate(tokens)}\n",
        "\n",
        "\n",
        "train_ds = TextDataset(train_text, WINDOW_SIZE, token_to_id)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "dev_ds = TextDataset(dev_text, WINDOW_SIZE, token_to_id)\n",
        "dev_dataloader = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "test_ds = TextDataset(test_text, WINDOW_SIZE, token_to_id)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pnf4aP9ywkjD"
      },
      "outputs": [],
      "source": [
        "model = GPT(vocab_size=len(tokens), max_len=WINDOW_SIZE)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HOZUqcOnwlIy"
      },
      "outputs": [],
      "source": [
        "wandb.watch(model, log_freq=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSeQTdOowrhS",
        "outputId": "93ade3d1-9d1d-4c9b-993f-fa9985bcefeb"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "epoch_loss = 0\n",
        "steps_n = 0\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        input, labels = batch[0].to(device), batch[1].to(device)\n",
        "        output, loss = model(input, labels)\n",
        "        epoch_loss += loss.item()\n",
        "        steps_n += 1\n",
        "    avg_loss = epoch_loss / steps_n\n",
        "expected_init_loss = -math.log(1 / 74)\n",
        "print(f\"initial train loss: {avg_loss:.3f}, with expected of {expected_init_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC3-JgvRwhxz",
        "outputId": "8b5dad32-7c3b-4b29-b5f7-b2e77d3f680d"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    val_epoch_loss = 0\n",
        "    steps_n = 0\n",
        "    val_steps_n = 0\n",
        "    test_epoch_loss = 0\n",
        "    test_steps_n = 0\n",
        "\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        input, labels = batch[0].to(device), batch[1].to(device)\n",
        "        output, loss = model(input, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        epoch_loss += loss.item()\n",
        "        steps_n += 1\n",
        "        run.log({\"train_loss\": loss.item()})\n",
        "\n",
        "    avg_loss = epoch_loss / steps_n\n",
        "    print(f\"epoch {epoch} train loss: {avg_loss:.3f}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dev_dataloader):\n",
        "            input, labels = batch[0].to(device), batch[1].to(device)\n",
        "            output, loss = model(input, labels)\n",
        "            val_epoch_loss += loss.item()\n",
        "            val_steps_n += 1\n",
        "\n",
        "        for batch in tqdm(test_dataloader):\n",
        "            input, labels = batch[0].to(device), batch[1].to(device)\n",
        "            output, loss = model(input, labels)\n",
        "            test_epoch_loss += loss.item()\n",
        "            test_steps_n += 1\n",
        "\n",
        "    avg_val_loss = val_epoch_loss / val_steps_n\n",
        "    avg_test_loss = test_epoch_loss / test_steps_n\n",
        "    print(f\"epoch {epoch} val loss: {avg_val_loss:.3f}\")\n",
        "    print(f\"epoch {epoch} test loss: {avg_test_loss:.3f}\")\n",
        "    run.log({\"epoch_train_loss\": avg_loss, \"epoch_val_loss\": avg_val_loss})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9eYiDoFRIou",
        "outputId": "4419745a-a0f1-4462-9c1b-a2a25f7abaec"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model/gpt.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "artifact = wandb.Artifact(\"model\", type=\"model\")\n",
        "artifact.add_file(\"model/gpt.pt\")\n",
        "run.log_artifact(artifact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()  # Ensure model is in evaluation mode\n",
        "prompt = \"Привет, любовь моя \"\n",
        "generated_text = generate_text(\n",
        "    model,\n",
        "    prompt,\n",
        "    device,\n",
        "    window_size=WINDOW_SIZE,\n",
        "    max_tokens=500,\n",
        "    temperature=1.0\n",
        ")\n",
        "print(generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNSJYgwicqPiUq3iula+gkx",
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
